{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43e832ca-34b1-423a-818b-bfe1594d2f1b",
   "metadata": {},
   "source": [
    "# CSS 206 Mini-Project Data Preprocess + Model demos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f39eb8e-140e-48c3-a20d-1aed00a94dc6",
   "metadata": {},
   "source": [
    "## Load data files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4a560c-086a-488e-9076-2ea34b51d341",
   "metadata": {},
   "source": [
    "Assume we have already downloaded csv files in a local folder named \"data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f0ed3e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import sklearn\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "aa799a94-33d6-4f2f-a749-0bfe92f6081e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marks\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3441: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# Load local csv files\n",
    "df_movies = pd.read_csv(\"./data/movies_metadata.csv\")\n",
    "df_keywords = pd.read_csv(\"./data/keywords.csv\")\n",
    "df_ratings = pd.read_csv(\"./data/ratings.csv\")\n",
    "\n",
    "# Download bechdel test score data\n",
    "address = \"http://bechdeltest.com/api/v1/getAllMovies\"\n",
    "response = requests.get(address)\n",
    "df_scores = pd.read_json(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de94fc9e-6ba8-4678-bd2b-38247e1398f3",
   "metadata": {},
   "source": [
    "## Combine dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc2668-3f8d-4ec2-b509-c7772faf0f67",
   "metadata": {},
   "source": [
    "**Let's have a look at dataframes and process id and imdb_id column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ade5acf4-b423-458f-b900-70d22d8f2ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult                     object\n",
      "belongs_to_collection     object\n",
      "budget                    object\n",
      "genres                    object\n",
      "homepage                  object\n",
      "id                        object\n",
      "imdb_id                   object\n",
      "original_language         object\n",
      "original_title            object\n",
      "overview                  object\n",
      "popularity                object\n",
      "poster_path               object\n",
      "production_companies      object\n",
      "production_countries      object\n",
      "release_date              object\n",
      "revenue                  float64\n",
      "runtime                  float64\n",
      "spoken_languages          object\n",
      "status                    object\n",
      "tagline                   object\n",
      "title                     object\n",
      "video                     object\n",
      "vote_average             float64\n",
      "vote_count               float64\n",
      "dtype: object\n",
      "(45466, 24)\n"
     ]
    }
   ],
   "source": [
    "# movies dataframe\n",
    "print(df_movies.dtypes)\n",
    "print(df_movies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1b31003b-ec60-4613-8a8e-536f2cf5bfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id           int64\n",
      "keywords    object\n",
      "dtype: object\n",
      "(46419, 2)\n"
     ]
    }
   ],
   "source": [
    "# keywords dataframe\n",
    "print(df_keywords.dtypes)\n",
    "print(df_keywords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5fb57338-429b-4e31-a883-b0c617702fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "userId         int64\n",
      "movieId        int64\n",
      "rating       float64\n",
      "timestamp      int64\n",
      "dtype: object\n",
      "(26024289, 4)\n"
     ]
    }
   ],
   "source": [
    "# rating dataframe\n",
    "print(df_ratings.dtypes)\n",
    "print(df_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "102f81cb-06e4-438a-98bb-d30bef430ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year       int64\n",
      "id         int64\n",
      "rating     int64\n",
      "imdbid    object\n",
      "title     object\n",
      "dtype: object\n",
      "(10493, 5)\n"
     ]
    }
   ],
   "source": [
    "# scores dataframe\n",
    "print(df_scores.dtypes)\n",
    "print(df_scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "347cb740-61a0-4f96-b966-98057cc94c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess \"id\" and \"imdb_id\" columns in df_movies\n",
    "\n",
    "# \"id\" in df_movies is str, \"id\" in df_ratings and df_keywords is int64\n",
    "df_movies[\"id\"] = pd.to_numeric(df_movies[\"id\"], errors=\"coerce\")\n",
    "df_movies.dropna(subset=[\"id\"], inplace=True)\n",
    "df_movies[\"id\"] = df_movies[\"id\"].astype(\"int64\")\n",
    "\n",
    "# imdbid in df_movies and df_scores both are str\n",
    "# imdbid in df_movies has additonal \"tt\" prefix, so we remove it\n",
    "df_movies[\"imdb_id\"] = df_movies[\"imdb_id\"].str[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7440a8d5-c88f-4ce6-a74e-1c902db70e18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data in s1 intersect s2: 45432\n",
      "Data in s1 intersect s3: 7565\n",
      "Data in s1 intersect s4: 7985\n"
     ]
    }
   ],
   "source": [
    "# Check number of data after intersection\n",
    "s1_id = set(df_movies[\"id\"])\n",
    "s1_imdb = set(df_movies[\"imdb_id\"])\n",
    "s2_id = set(df_keywords[\"id\"])\n",
    "s3_id = set(df_ratings[\"movieId\"])\n",
    "s4_imdb = set(df_scores[\"imdbid\"])\n",
    "\n",
    "print(f\"Data in s1 intersect s2: {len(s1_id & s2_id)}\")\n",
    "print(f\"Data in s1 intersect s3: {len(s1_id & s3_id)}\")\n",
    "print(f\"Data in s1 intersect s4: {len(s1_imdb & s4_imdb)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85202af3-083f-43af-8feb-106b296a6efa",
   "metadata": {},
   "source": [
    "There will be even less data if we combine 4 dataframes together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c0469-2a0f-4f5f-b77f-7ce405ee15a7",
   "metadata": {},
   "source": [
    "**Then, let's merge df_movies with other 3 dataframes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0c8a8f98-520c-4af7-93e7-34d26d7034d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine df_movies and df_keywords together\n",
    "# Combine and retain only matching rows\n",
    "df_movies = df_movies.merge(df_keywords, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dd8aaa19-83d9-4c6a-a15c-28104d679077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine df_movies and df_ratings together\n",
    "# Calculate average ratings\n",
    "df_ratings = df_ratings.groupby(\"movieId\")[\"rating\"].mean().reset_index()\n",
    "df_ratings.columns = [\"id\", \"rating\"]\n",
    "\n",
    "# Combine and retain only matching rows\n",
    "df_movies = df_movies.merge(df_ratings, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3f5abbb6-ca35-4229-a038-956892ab383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine df_movies and df_scores together\n",
    "df_scores = df_scores[[\"imdbid\", \"rating\"]]\n",
    "df_scores.columns = [\"imdb_id\", \"bechdel_score\"]\n",
    "\n",
    "# Combine and retain only matching rows\n",
    "df_movies = df_movies.merge(df_scores, on=\"imdb_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717eab1-5e9c-4b5c-8cd4-6b33fddbda0f",
   "metadata": {},
   "source": [
    "**There only 2k+ rows data now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "cd6e0b94-1043-42fe-a8a0-2a48150017c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to save memory \n",
    "del df_keywords\n",
    "del df_ratings\n",
    "del df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d865f-15ee-4919-b68b-c3267e5df53f",
   "metadata": {},
   "source": [
    "## Change data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a048fdb9-b974-48d3-8e93-fd1ea8370e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adult                     object\n",
      "belongs_to_collection     object\n",
      "budget                    object\n",
      "genres                    object\n",
      "homepage                  object\n",
      "id                         int64\n",
      "imdb_id                   object\n",
      "original_language         object\n",
      "original_title            object\n",
      "overview                  object\n",
      "popularity                object\n",
      "poster_path               object\n",
      "production_companies      object\n",
      "production_countries      object\n",
      "release_date              object\n",
      "revenue                  float64\n",
      "runtime                  float64\n",
      "spoken_languages          object\n",
      "status                    object\n",
      "tagline                   object\n",
      "title                     object\n",
      "video                     object\n",
      "vote_average             float64\n",
      "vote_count               float64\n",
      "keywords                  object\n",
      "rating                   float64\n",
      "bechdel_score              int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check column names and types in df_movies\n",
    "print(df_movies.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed25d97",
   "metadata": {},
   "source": [
    "# Add categorical data\n",
    "`genres`, `spoken_languages`, `original_language`, `production_countries`\n",
    "\n",
    "Ignoring `production_companies` because there are more unique values than there are rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6076102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies['spoken_languages']=df_movies['spoken_languages'].apply(eval).apply(lambda l: [x['name'] for x in l])\n",
    "df_movies['genres']=df_movies['genres'].apply(eval).apply(lambda l: [x['name'] for x in l])\n",
    "df_movies['production_countries']=df_movies['production_countries'].apply(eval).apply(lambda l: [x['name'] for x in l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "379a3a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = set()\n",
    "df_movies['genres'].apply(genres.update)\n",
    "len(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1254d55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_language = set()\n",
    "df_movies['original_language'].dropna().apply(original_language.add)\n",
    "len(original_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "5fb1a7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spoken_languages = set()\n",
    "df_movies['spoken_languages'].apply(spoken_languages.update)\n",
    "len(spoken_languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "34b13ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "production_countries = set()\n",
    "df_movies['production_countries'].apply(production_countries.update)\n",
    "len(production_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "654e49e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# production_companies = set()\n",
    "# df_movies['production_companies'].apply(lambda l: production_companies.update([x['name'] for x in l]))\n",
    "# len(production_companies)\n",
    "# 2813"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a233763",
   "metadata": {},
   "source": [
    "For multi-valued categorical variables, decompose into 1-hot columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2af1cc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marks\\AppData\\Local\\Temp/ipykernel_9176/4122275542.py:11: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_movies[varcol]=0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>production_countries_Netherlands Antilles</th>\n",
       "      <th>production_countries_Bulgaria</th>\n",
       "      <th>production_countries_Peru</th>\n",
       "      <th>production_countries_Bahamas</th>\n",
       "      <th>production_countries_Canada</th>\n",
       "      <th>production_countries_Finland</th>\n",
       "      <th>production_countries_India</th>\n",
       "      <th>production_countries_United States of America</th>\n",
       "      <th>production_countries_Hong Kong</th>\n",
       "      <th>production_countries_Chile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000.0</td>\n",
       "      <td>[Animation, Comedy, Family]</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000.0</td>\n",
       "      <td>[Adventure, Fantasy, Family]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60000000.0</td>\n",
       "      <td>[Action, Crime, Drama, Thriller]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>949</td>\n",
       "      <td>0113277</td>\n",
       "      <td>en</td>\n",
       "      <td>Heat</td>\n",
       "      <td>Obsessive master thief, Neil McCauley leads a ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 645, 'name': 'James Bond Collection', '...</td>\n",
       "      <td>58000000.0</td>\n",
       "      <td>[Adventure, Action, Thriller]</td>\n",
       "      <td>http://www.mgm.com/view/movie/757/Goldeneye/</td>\n",
       "      <td>710</td>\n",
       "      <td>0113189</td>\n",
       "      <td>en</td>\n",
       "      <td>GoldenEye</td>\n",
       "      <td>James Bond must unmask the mysterious head of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98000000.0</td>\n",
       "      <td>[Action, Adventure]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1408</td>\n",
       "      <td>0112760</td>\n",
       "      <td>en</td>\n",
       "      <td>Cutthroat Island</td>\n",
       "      <td>Morgan Adams and her slave, William Shaw, are ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection      budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000.0   \n",
       "1  False                                                NaN  65000000.0   \n",
       "2  False                                                NaN  60000000.0   \n",
       "3  False  {'id': 645, 'name': 'James Bond Collection', '...  58000000.0   \n",
       "4  False                                                NaN  98000000.0   \n",
       "\n",
       "                             genres  \\\n",
       "0       [Animation, Comedy, Family]   \n",
       "1      [Adventure, Fantasy, Family]   \n",
       "2  [Action, Crime, Drama, Thriller]   \n",
       "3     [Adventure, Action, Thriller]   \n",
       "4               [Action, Adventure]   \n",
       "\n",
       "                                       homepage    id  imdb_id  \\\n",
       "0          http://toystory.disney.com/toy-story   862  0114709   \n",
       "1                                           NaN  8844  0113497   \n",
       "2                                           NaN   949  0113277   \n",
       "3  http://www.mgm.com/view/movie/757/Goldeneye/   710  0113189   \n",
       "4                                           NaN  1408  0112760   \n",
       "\n",
       "  original_language    original_title  \\\n",
       "0                en         Toy Story   \n",
       "1                en           Jumanji   \n",
       "2                en              Heat   \n",
       "3                en         GoldenEye   \n",
       "4                en  Cutthroat Island   \n",
       "\n",
       "                                            overview  ...  \\\n",
       "0  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "1  When siblings Judy and Peter discover an encha...  ...   \n",
       "2  Obsessive master thief, Neil McCauley leads a ...  ...   \n",
       "3  James Bond must unmask the mysterious head of ...  ...   \n",
       "4  Morgan Adams and her slave, William Shaw, are ...  ...   \n",
       "\n",
       "   production_countries_Netherlands Antilles production_countries_Bulgaria  \\\n",
       "0                                          0                             0   \n",
       "1                                          0                             0   \n",
       "2                                          0                             0   \n",
       "3                                          0                             0   \n",
       "4                                          0                             0   \n",
       "\n",
       "  production_countries_Peru production_countries_Bahamas  \\\n",
       "0                         0                            0   \n",
       "1                         0                            0   \n",
       "2                         0                            0   \n",
       "3                         0                            0   \n",
       "4                         0                            0   \n",
       "\n",
       "  production_countries_Canada  production_countries_Finland  \\\n",
       "0                           0                             0   \n",
       "1                           0                             0   \n",
       "2                           0                             0   \n",
       "3                           0                             0   \n",
       "4                           0                             0   \n",
       "\n",
       "   production_countries_India production_countries_United States of America  \\\n",
       "0                           0                                             1   \n",
       "1                           0                                             1   \n",
       "2                           0                                             1   \n",
       "3                           0                                             1   \n",
       "4                           0                                             1   \n",
       "\n",
       "  production_countries_Hong Kong production_countries_Chile  \n",
       "0                              0                          0  \n",
       "1                              0                          0  \n",
       "2                              0                          0  \n",
       "3                              0                          0  \n",
       "4                              0                          0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_vars = {\n",
    "    'genres': genres,\n",
    "    'spoken_languages': spoken_languages,\n",
    "    'production_countries': production_countries\n",
    "}\n",
    "onehot_cols = []\n",
    "for varname, values in categorical_vars.items():\n",
    "    for var in values:\n",
    "        varcol = varname+'_'+var\n",
    "        onehot_cols.append(varcol)\n",
    "        df_movies[varcol]=0\n",
    "        has_var = df_movies[varname].apply(lambda l: var in l)\n",
    "        df_movies.loc[has_var, varcol]=1\n",
    "\n",
    "genre_cols = [col for col in onehot_cols if 'genre' in col]\n",
    "cntry_cols = [col for col in onehot_cols if 'countries' in col]\n",
    "lang_cols = [col for col in onehot_cols if 'spoken' in col]\n",
    "\n",
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af34777",
   "metadata": {},
   "source": [
    "# Add bag of word columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd27aad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20966642 0.20343705 0.2114386  0.17224279 0.19495868]\n",
      "[0.25561468 0.25294464 0.25817429 0.23188406 0.21433009]\n",
      "[0.19696272 0.20101679 0.20822134 0.19114082 0.19763775]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "df_movies['keyword_str'] = df_movies['keywords'].apply(eval).apply(lambda l: ' '.join(x['name'] for x in l))\n",
    "word_columns = [\"overview\", \"keyword_str\", \"tagline\"]\n",
    "stemmed_cols = []\n",
    "for col in word_columns:\n",
    "    stemmed_col = df_movies[col].apply(lambda s: ' '.join([stemmer.stem(w) for w in s.split()]) if type(s) is str else np.nan)\n",
    "\n",
    "    bnb = BernoulliNB()\n",
    "    bow = vectorizer.fit_transform(stemmed_col.dropna())\n",
    "    y = df_movies['bechdel_score'].loc[stemmed_col.dropna().index]\n",
    "    print(cross_validate(estimator=bnb, X=bow, y=y, scoring='f1_macro')['test_score'])\n",
    "    # print(stemmed_col.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "774473f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert budget and popularity column from string to float\n",
    "df_movies[\"budget\"] = df_movies[\"budget\"].astype(float)\n",
    "df_movies[\"popularity\"] = df_movies[\"popularity\"].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "24362d0c-5774-4967-8b98-0e40d5cea382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 147\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>popularity</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>rating</th>\n",
       "      <th>genres_Mystery</th>\n",
       "      <th>genres_Comedy</th>\n",
       "      <th>genres_Drama</th>\n",
       "      <th>...</th>\n",
       "      <th>production_countries_Bulgaria</th>\n",
       "      <th>production_countries_Peru</th>\n",
       "      <th>production_countries_Bahamas</th>\n",
       "      <th>production_countries_Canada</th>\n",
       "      <th>production_countries_Finland</th>\n",
       "      <th>production_countries_India</th>\n",
       "      <th>production_countries_United States of America</th>\n",
       "      <th>production_countries_Hong Kong</th>\n",
       "      <th>production_countries_Chile</th>\n",
       "      <th>bechdel_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30000000.0</td>\n",
       "      <td>21.946943</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>3.598930</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65000000.0</td>\n",
       "      <td>17.015539</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>3.760163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60000000.0</td>\n",
       "      <td>17.924927</td>\n",
       "      <td>187436818.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1886.0</td>\n",
       "      <td>3.905544</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58000000.0</td>\n",
       "      <td>14.686036</td>\n",
       "      <td>352194034.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>2.740334</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>98000000.0</td>\n",
       "      <td>7.284477</td>\n",
       "      <td>10017322.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>137.0</td>\n",
       "      <td>3.710181</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       budget  popularity      revenue  runtime  vote_average  vote_count  \\\n",
       "0  30000000.0   21.946943  373554033.0     81.0           7.7      5415.0   \n",
       "1  65000000.0   17.015539  262797249.0    104.0           6.9      2413.0   \n",
       "2  60000000.0   17.924927  187436818.0    170.0           7.7      1886.0   \n",
       "3  58000000.0   14.686036  352194034.0    130.0           6.6      1194.0   \n",
       "4  98000000.0    7.284477   10017322.0    119.0           5.7       137.0   \n",
       "\n",
       "     rating  genres_Mystery  genres_Comedy  genres_Drama  ...  \\\n",
       "0  3.598930               0              1             0  ...   \n",
       "1  3.760163               0              0             0  ...   \n",
       "2  3.905544               0              0             1  ...   \n",
       "3  2.740334               0              0             0  ...   \n",
       "4  3.710181               0              0             0  ...   \n",
       "\n",
       "   production_countries_Bulgaria  production_countries_Peru  \\\n",
       "0                              0                          0   \n",
       "1                              0                          0   \n",
       "2                              0                          0   \n",
       "3                              0                          0   \n",
       "4                              0                          0   \n",
       "\n",
       "   production_countries_Bahamas  production_countries_Canada  \\\n",
       "0                             0                            0   \n",
       "1                             0                            0   \n",
       "2                             0                            0   \n",
       "3                             0                            0   \n",
       "4                             0                            0   \n",
       "\n",
       "   production_countries_Finland  production_countries_India  \\\n",
       "0                             0                           0   \n",
       "1                             0                           0   \n",
       "2                             0                           0   \n",
       "3                             0                           0   \n",
       "4                             0                           0   \n",
       "\n",
       "   production_countries_United States of America  \\\n",
       "0                                              1   \n",
       "1                                              1   \n",
       "2                                              1   \n",
       "3                                              1   \n",
       "4                                              1   \n",
       "\n",
       "   production_countries_Hong Kong  production_countries_Chile  bechdel_score  \n",
       "0                               0                           0              1  \n",
       "1                               0                           0              3  \n",
       "2                               0                           0              2  \n",
       "3                               0                           0              3  \n",
       "4                               0                           0              1  \n",
       "\n",
       "[5 rows x 155 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick columns that we need to train our model\n",
    "cont_cols = [\"budget\", \"popularity\", \"revenue\", \"runtime\", \"vote_average\", \"vote_count\", \"rating\"]\n",
    "print(len(cont_cols), len(onehot_cols))\n",
    "df_train = df_movies[cont_cols+onehot_cols+['bechdel_score']]\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af6d5ec-b360-4ba0-afe8-256ccab1337f",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3ed52a5c-307c-49f4-9ea9-df18ab749fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2167, 7), (2167, 147), array([0., 1.]), (2167,), array([0, 1, 2, 3]))"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = df_train.values\n",
    "\n",
    "# Shuffle data, you may change seed\n",
    "np.random.seed(1)\n",
    "np.random.shuffle(data)\n",
    "\n",
    "# split features and label\n",
    "x_cont = data[:, :len(cont_cols)]\n",
    "x_cat = data[:, len(cont_cols):-1]\n",
    "y = data[:, -1]\n",
    "\n",
    "# Change data type\n",
    "x_cont = x_cont.astype(np.float32)\n",
    "y = y.astype(np.int32) # We use float in regression and int in classification\n",
    "x_cont.shape, x_cat.shape, np.unique(x_cat), y.shape, np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "5022b143-0cad-452d-96dd-b84044c7a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train dataset and test dataset, you may change the ratio\n",
    "train_ratio = 0.9\n",
    "threshold = int(train_ratio * len(y))\n",
    "x_cont_train = x_cont[:threshold, :]\n",
    "x_cont_test = x_cont[threshold:, :]\n",
    "\n",
    "x_cat_train = x_cat[:threshold, :]\n",
    "x_cat_test = x_cat[threshold:, :]\n",
    "\n",
    "y_train = y[:threshold]\n",
    "y_test = y[threshold:]\n",
    "\n",
    "# Feature scaling with Z-score\n",
    "train_mean, train_std = np.mean(x_cont_train, axis=0), np.std(x_cont_train, axis=0)\n",
    "x_cont_train = (x_cont_train - train_mean) / train_std\n",
    "x_cont_test  = (x_cont_test  - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4a3d5195",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_all_train = np.concatenate([x_cont_train, x_cat_train], axis=1)\n",
    "x_all_test = np.concatenate([x_cont_test, x_cat_test], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e18ce8-05e5-458d-bf2d-d3a3de00826e",
   "metadata": {},
   "source": [
    "Then you can go training model with (x_train, y_train), and test model with (x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d4880f-01bd-4671-b631-b4adf038b985",
   "metadata": {},
   "source": [
    "## Train models (demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "eee5a0a3-ef75-4388-aed2-e5a2721c39ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Continuous featues\n",
      "SVM: Loss- 1.35, Accuracy- 0.55, f1- 0.23\n",
      "RF: Loss- 1.33, Accuracy- 0.52, f1- 0.27\n",
      "DT: Loss- 1.37, Accuracy- 0.54, f1- 0.20\n",
      "GNB: Loss- 1.39, Accuracy- 0.53, f1- 0.27\n",
      "Categorical featues\n",
      "SVM: Loss- 1.30, Accuracy- 0.55, f1- 0.29\n",
      "RF: Loss- 1.34, Accuracy- 0.50, f1- 0.32\n",
      "DT: Loss- 1.33, Accuracy- 0.53, f1- 0.27\n",
      "BNB: Loss- 1.31, Accuracy- 0.53, f1- 0.31\n",
      "All features\n",
      "SVM: Loss- 1.32, Accuracy- 0.55, f1- 0.27\n",
      "RF: Loss- 1.31, Accuracy- 0.53, f1- 0.30\n",
      "DT: Loss- 1.37, Accuracy- 0.53, f1- 0.25\n",
      "BNB: Loss- 1.29, Accuracy- 0.54, f1- 0.34\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import root_mean_squared_error, f1_score\n",
    "\n",
    "print(\"Continuous featues\")\n",
    "\n",
    "# Support vector machine\n",
    "model = SVC()\n",
    "model.fit(x_cont_train, y_train)\n",
    "y_pred = model.predict(x_cont_test)\n",
    "\n",
    "loss = root_mean_squared_error(y_test, y_pred)\n",
    "acc = np.mean(y_pred[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"SVM: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")\n",
    "\n",
    "# Random forest\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_cont_train, y_train)\n",
    "y_pred = model.predict(x_cont_test)\n",
    "\n",
    "loss = root_mean_squared_error(y_test, y_pred)\n",
    "acc = np.mean(y_pred[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"RF: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")\n",
    "\n",
    "# Random forest\n",
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(x_cont_train, y_train)\n",
    "y_pred = model.predict(x_cont_test)\n",
    "\n",
    "loss = root_mean_squared_error(y_test, y_pred)\n",
    "acc = np.mean(y_pred[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"DT: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")\n",
    "\n",
    "# Gaussian naive bayes\n",
    "model = GaussianNB()\n",
    "model.fit(x_cont_train, y_train)\n",
    "y_pred = model.predict(x_cont_test)\n",
    "\n",
    "loss = root_mean_squared_error(y_test, y_pred)\n",
    "acc = np.mean(y_pred[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"GNB: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")\n",
    "\n",
    "print(\"Categorical featues\")\n",
    "\n",
    "# Support vector machine\n",
    "model = SVC()\n",
    "model.fit(x_cat_train, y_train)\n",
    "y_pred = model.predict(x_cat_test)\n",
    "\n",
    "loss = root_mean_squared_error(y_test, y_pred)\n",
    "acc = np.mean(y_pred[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"SVM: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")\n",
    "\n",
    "# Random forest\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_cat_train, y_train)\n",
    "y_pred = model.predict(x_cat_test)\n",
    "\n",
    "loss = root_mean_squared_error(y_test, y_pred)\n",
    "acc = np.mean(y_pred[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"RF: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")\n",
    "\n",
    "# Random forest\n",
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(x_cat_train, y_train)\n",
    "y_pred = model.predict(x_cat_test)\n",
    "\n",
    "loss = root_mean_squared_error(y_test, y_pred)\n",
    "acc = np.mean(y_pred[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"DT: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")\n",
    "\n",
    "# Bernoulli naive bayes\n",
    "model = BernoulliNB()\n",
    "model.fit(x_cat_train, y_train)\n",
    "y_pred = model.predict(x_cat_test)\n",
    "\n",
    "loss = root_mean_squared_error(y_test, y_pred)\n",
    "acc = np.mean(y_pred[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"BNB: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")\n",
    "\n",
    "print(\"All features\")\n",
    "\n",
    "# Support vector machine\n",
    "model = SVC()\n",
    "model.fit(x_all_train, y_train)\n",
    "y_pred = model.predict(x_all_test)\n",
    "\n",
    "loss = root_mean_squared_error(y_test, y_pred)\n",
    "acc = np.mean(y_pred[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"SVM: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")\n",
    "\n",
    "# Random forest\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_all_train, y_train)\n",
    "y_pred = model.predict(x_all_test)\n",
    "\n",
    "loss = root_mean_squared_error(y_test, y_pred)\n",
    "acc = np.mean(y_pred[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"RF: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")\n",
    "\n",
    "# Random forest\n",
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(x_all_train, y_train)\n",
    "y_pred = model.predict(x_all_test)\n",
    "\n",
    "loss = root_mean_squared_error(y_test, y_pred)\n",
    "acc = np.mean(y_pred[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"DT: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")\n",
    "\n",
    "# Bernoulli naive bayes\n",
    "model = BernoulliNB()\n",
    "model.fit(x_all_train, y_train)\n",
    "y_pred = model.predict(x_all_test)\n",
    "\n",
    "loss = root_mean_squared_error(y_test, y_pred)\n",
    "acc = np.mean(y_pred[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(f\"BNB: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "cd752f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive: Loss- 1.38, Accuracy- 0.53, f1- 0.17\n"
     ]
    }
   ],
   "source": [
    "y_naive = np.full_like(y_test, fill_value=3)\n",
    "loss = root_mean_squared_error(y_test, y_naive)\n",
    "acc = np.mean(y_naive[:] == y_test[:])\n",
    "f1 = f1_score(y_test, y_naive, average='macro')\n",
    "print(f\"Naive: Loss- {loss:.2f}, Accuracy- {acc:.2f}, f1- {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
